# DATA601
Relevant Literatures
Agarwal, R., Singh, A., Zhang, L. M., Bohnet, B., Rosias, L., Chan, S., ... & Larochelle, H. (2024). Many-shot in-context learning. arXiv preprint arXiv:2404.11018.
Baker, M. & G. Saldanha (ed.) (1998/2009). Routledge Encyclopedia of Translation Studies. Routledge. 
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33, 1877-1901.
Chen, Q., & Li, J. (2023). Comparative Study of Machine Translation and Artificial Translation in the Medical Field from the Perspective of Communicative Translation Theory—Taking the Instructions of Chinese Medicine as an Example. Modern Linguistics, 11, 5892.
Dettmers, T., Pagnoni, A., Holtzman, A., & Zettlemoyer, L. (2024). Qlora: Efficient finetuning of quantized llms. Advances in Neural Information Processing Systems, 36.
Gemini Team, Georgiev, P., Lei, V. I., Burnell, R., Bai, L., Gulati, A., ... & Batsaikhan, B. O. (2024). Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530.
Google. (2024, February 1). Google Gemini: Next-generation model. Google AI Blog. https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#gemini-15
Lee, J., Chen, A., Dai, Z., Dua, D., Sachan, D. S., Boratko, M., ... & Guu, K. (2024). Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?. arXiv preprint arXiv:2406.13121.
Møller, A. G., & Aiello, L. M. (2024). Prompt Refinement or Fine-tuning? Best Practices for using LLMs in Computational Social Science Tasks. arXiv preprint arXiv:2408.01346.
Ovadia, O., Brief, M., Mishaeli, M., & Elisha, O. (2023). Fine-tuning or retrieval? comparing knowledge injection in llms. arXiv preprint arXiv:2312.05934.
Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002). Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics (pp. 311-318).
Post, M. (2018). A call for clarity in reporting BLEU scores. arXiv preprint arXiv:1804.08771.
Van Leuven-Zwart, K. (1989). Translation and original: Similarities and dissimilarities, I. Target. International Journal of Translation Studies, 1(2), 151-181.
Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.
